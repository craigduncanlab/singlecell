---
title: "Seurat Hacking Part 2:  - An In Depth Look"
author: "Craig Duncan"
date: "11-14 March 2021; 6 April 2021"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Evolution of Seurat through the tutorials

A useful index to old materials:
https://satijalab.org/seurat/articles/archive.html

One of the original tutorials (version 1, when the input was a matrix) is here:
https://www.dropbox.com/s/dl/bwbjelhrhf8cxq8/pbmc-tutorial.Rmd

# This manual focusses on Seurat, and the R environment, but it is not an ordinary tutorial

My personal preference is to include some information about software implementation and scientific methodology for the use of Seurat.  

This manual's contents are more detailed than the usual tutorial-styled introduction to Seurat with a simple 'follow this recipe' approach like the [GencoreTute](https://learn.gencore.bio.nyu.edu/single-cell-rnaseq/seurat-part-1-loading-the-data/).

On the other hand, some of what I think useful (such as understanding how a Seurat object is put together, so you can manipulate the data wisely with R if you need to), will require being familiar with some of R's concepts regarding classes,objects and slots, and how R utilises them (for example, how does the code on Github actually make the Seurat S4 object : it's S4 not S3 in the latest version).  Be aware that these sort of questions may also be answered by reading the Seurat developer's guide, which is actually a wiki page attached to the main code pages: [DevGuide](https://github.com/satijalab/seurat/wiki).  Pages are in different states of update.  Content on that main page includes this description (and other info relevant to version 3.0 not 4.0):

```
This guide is to help developers understand how the Seurat object is structured, how to interact with the object and access data from it, and how to develop new methods for Seurat objects.
```

One of the people working on this is Paul Hoffman. [LinkedIn](https://www.linkedin.com/in/pauljhoffman), and he answers technical development questions on github using the name @mohaveazure.  He's based in 2 labs in New York [HoffmanGithub](https://github.com/mojaveazure) [HoffmanWeb](https://keybase.io/mojaveazure) [HoffmanTwitter](https://twitter.com/mojaveazure) [RepositoryGGSeurat](https://mojaveazure.github.io/ggseurat/)

# What is a Seurat object?  

A Seurat object is a large, complex, customised R Class with built-in features for single cell genomic analysis and visualisation.  Since the object itself is full of many custom functions and data-structures for analysis, it is offered by its authors as a 'turn-key' software solution for biological scientists engaged in single-cell analysis, starting at the point at which gene-vs-cell counts have been obtained from a genetic sequencing provider (or have been self-generated in other ways).  

A Seurat object is also an R language object.  It is therefore dependent upon, and integrated with, the use of the R programming language, functions, data types and operators.  These will be familiar to those who are already familiar with the R environment.  

The Seurat object anticipates the needs of scientists for data storage of genes-v-cell counts, analysis of gene expression data, and visualisation.  To make this easier, it provides a standard scheme for storing existing count data (using Assays), and also provides a set of simple procedures and functions to help carry out the scientific analysis.  This script-based system does not prompt the user, so the user's ability to set up the data, apply functions in the correct order, and write useful scripts depends on the user's own knowledge and understanding.  

# How Seurat objects are put together

The developer's guide has a useful list of what's inside: [SeuratObject](https://github.com/satijalab/seurat/wiki/Seurat).  R Developers can note that "Most functions in Seurat are written using S3-style generics and methods, but the package is compatible with both the S3 and S4 object systems." [S3generics](https://github.com/satijalab/seurat/wiki/S3-methods)

The entire file structure is usefully explained here: [SeuratFileStruct](https://github.com/satijalab/seurat/wiki/Source-Code-File-Structure-and-Organization).  My own notes on this, before I located the Developer's guide, appear below:

## notes on the S3/S4 aspects of Seurat objects

At some point, Seurat object was S3?  https://rdrr.io/cran/SeuratObject/man/CreateSeuratObject.html
But there are S4 references here: [CRAN](https://rdrr.io/cran/SeuratObject/f/README.md)
It seems that by Seurat v3.0 there was a 'Seurat' (uppercase) object in S4, and this was exported to allow other packages to use it by including it as an export in the NAMESPACE commands (see [issues990](https://github.com/satijalab/seurat/issues/990))
It turns out the Developer's Guide (rather than User Guide) is very good with this sort of internal stuff: [DevGuide](https://github.com/satijalab/seurat/wiki)

It seems that in v3 at least, the S4 Seurat object was created like this:
new(Class = "seurat", raw.data = raw.data, is.expr = is.expr,...
[source](https://github.com/satijalab/seurat/issues/1411)

If interested in what is going on in the code module that produces violin plots, you can have  look at the source file here:
https://github.com/satijalab/seurat/blob/master/R/visualization.R
There is a line about 570 lines in that starts with:
VlnPlot <- function(

The 'Read10X' function definition code is found in this file:
https://github.com/satijalab/seurat/blob/master/R/preprocessing.R
It doesn't rely on a Seurat object at this stage.  As it says, its purpose is to "Combine all the data from different directories into one big matrix".  There is a reference to 'CellRanger' in this code, so it presupposes that the input files are CellRanger output.

There is another significant file that contains details for intermediate formats, converting from other formats to Seurat (as functions)
https://github.com/satijalab/seurat/blob/master/R/objects.R
The first 300 lines set s4 classes e.g. with lines like: 
IntegrationData <- setClass(...

After that, there are function definitions
e.g. the line:
as.SingleCellExperiment.Seurat <- function(x, assay = NULL, ...) {

You can also see the CalcN function here (line 2292), which performs the automatic calculation of counts of nCount and nFeature from the Seurat object's 'count' slot:
CalcN <- function(object) {

'nb CalcN and ExtractField look like functions needed for CreateSeuratObject'

In original version, namespace/scope was expressed in R with Seurat:: and this would pick up any functions defined inside the package's .R files??  Like this: 
raw_data <- Seurat::Read10X( data.dir = "~/outs/filtered_feature_bc_matrix/" )

The use of R's generics here, to indirectly call functions with respect to the input object:
https://github.com/satijalab/seurat/blob/master/R/generics.R

A little bit of data/discussion in this file about the SeuratObject class, and the Assay class etc.
Seems to create an interface for SeuratObject but nothing concrete:
https://github.com/satijalab/seurat/blob/master/R/reexports.R
Includes scope lines like:
SeuratObject::CreateSeuratObject

Documentation for specific functions is generated by roxygen2 from comments in the .R files code (a bit like the javadocs workflow).
The result is found in .Rd files like this:
https://github.com/satijalab/seurat/blob/master/man/Read10X.Rd

As a minimum, when working with R these packages should be installed and available:

```{R}
# install.packages('Seurat')
library(dplyr)
library(Seurat) 
library(Matrix)
```

# Overview of the Seurat object

The Seurat object is not the only R Class (object) provided by the package, but it is the one that encapsulates all the other custom R objects.  It is the outermost R-language object in the complex data structures offered by the package.  Internally, it has several data objects and book-keeping structures.  These can be used individually, and together, to hold information, to update gene and cell information, and to use this information for visualisation and filtering through to the end of the analysis.

Before discussing the Seurat object further, it is useful to discuss what gene-vs-cell count information it is designed to accept, and how that information might need to be verified and filtered before deciding to import it into a Seurat object.

Here's the Satija lab's [wiki description](https://github.com/satijalab/seurat/wiki):

```
The Seurat object is a class allowing for the storage and manipulation of single-cell data. Previous version of the Seurat object were designed primarily with scRNA-seq data in mind. However, with the development of new technologies allowing for multiple modes of data to be collected from the same set of cells, we have redesigned the Seurat 3.0 object to allow for greater flexibility to work with all these data types in a cohesive framework.

At the top level, the Seurat object serves as a collection of Assay and DimReduc objects, representing expression data and dimensionality reductions of the expression data, respectively. The Assay objects are designed to hold expression data of a single type, such as RNA-seq gene expression, CITE-seq ADTs, cell hashtags, or imputed gene values. DimReduc objects represent transformations of the data contained within the Assay object(s) via various dimensional reduction techniques such as PCA. For class-specific details, including more in depth description of the slots, please see the wiki sections for each class.
```

## Classes, objects and slots in R

At this point, it is worth a brief note to say that Seurat is using class and object-orientated concepts that have specific names in R.

R has 3 types of classes, not one.  S3, S4 and reference.

S3 are simple classes (everything in R is an 'object' anyway).  By setting a name for your object, you create a class for it:
Let's say your object 's' is already a 'list'.  You create a class S3 like this:
class(s) = "Student".  There are no getters and setters.

S4 objects are more complex than S3: more like conventional OOP classes in OOP languages like Java. 

The S4 class is explicitly defined by the setClass() method. It takes arguments for the name of the class and the list of 'slots' (in R, data fields/member variables are called slots.  They must have existing data types before being specified for the class constructor/design)

if you see the function setOldClass() then this means an S3 class is being included in an S4 class.[tute](https://astrostatistics.psu.edu/su07/R/html/methods/html/setClass.html)

There are some other odd features with class creation in R (it seems to resemble prototyping in javascript a bit).  Functions that specify functions of the class with setMethod must override an existing function: [tute](https://programmingpages.wordpress.com/2014/08/31/creating-classes-in-r/)

To create an object of this class, use the new() method.

# Creating and saving Seurat objects

A Seurat object can be created from suitable gene-vs-cell count data.  This can be, for example, (a) 10X data (with 3 source files), or (b) a raw sparse matrix with cell names for row names and genes for the column names, with the gene expression counts filling up the data in the matrix.

The Seurat package is designed so that any further analysis, filtering and classification, the 'state' of the scientific work will be captured in the state of the Seurat object.  

Irrespective of whether or not this 'snapshot' of the Seurat object's state can be saved and reloaded, if a user has maintained an R script file recording all the steps taken to create, update and use the Seurat object, then this scientist or another user can follow the path taken to arrive at the same state of data analysis.

# What the Seurat package cannot do

The Seurat package is not designed for producing the initial gene-vs-cell counts from sequencing data.  These data files with gene-cell counts usually require higher computing resources and information about the genes that are being counted, as well as the cell identification markers (barcodes) in source sequencing data.   That means that if only raw transcriptome sequences have been obtained from a sequencing provider (FASTQ files or even BCL files) then users wanting to work with Seurat will have to carry out additional work to obtain gene-vs-cell counts first.

# Processes for sequencing and counting that need to be completed prior to using Seurat

Prior to using Seurat, biological data must already have been converted to digital data, and this digital sequencing data must have also been compared to other information about genes and organism genomes to give labels to the genes that the scientists want to use to count the genes present in cells.

The sequencing stage of the single-cell analysis process requires both the individual molecular fragments of RNA or DNA and the cells from which they originated (barcoded cells) to be marked with molecular identifiers (themselves biological 'codes' capable of being read in sequencing machines).  The marked-up genetic information forms a biological 'library', and from this digital data is extracted by the sequencing machine.  The output is in the form of many base-pair 'reads' (stored in computer files) which describe the genetic sequences inside the fragments, as well as the barcodes.  These reads are contained in BCL and later, FASTQ format files.  Sometimes, the reads are in 2 directions, to help with piecing together fragments later in the process.

The single cell analysis for gene sequencing data will often begin by completing a count of the thousands of individually identified cells, and thousands of genes that are present in the digital sequencing data produced on high-throughput sequencing matchines.  However, this counting cannot be done immediately, due to the need to re-assemble genetic information from fragments (e.g. in FASTQ files), and also to link that information to libraries containing information about 'genes', their source, and their functions.

## FASTQ files and quality testing

The production of the digital sequencing reads is very early in the single cell analysis process. This digital output might itself contain evidence that the process has not been carried out as intended, or data is missing.   

Some kind of quality assessment of this information is necessary, both to validate the intentions of the experiment, as well as the practical achievement of converting biological information to digital data.  The ways in which biological quality or experimental problems can be tested, identified and satisfied requires a knowledge of the library-preparation process, and some ability to indentify signs of bias, experimental failure, or unusual quantities in the sequencing data.  When a certain read-length is expected, for example, then outlying lengths of fragments in the data would need further attention.

## Gene reference files (GFF3, GTF)

Genes are representations of our knowledge of genetic sequences (sub-parts of an entire genome of an organism) that have a biological significance.  Over time, they have been given names that allow them to be identified within, and sometimes across, different species of organism.  

Genes are not automatically identified as such in the output of a sequencing machine.  At the moment, part of the reason is that the sequencing machine produces random fragments of genetic information (even if the length is constant).  These fragments could be parts of one or more genes, and initially it is not known which.  

Another important aspect of genes is that they were initially associated mostly with the 1-dimensional sequence of DNA or RNA codes, rather than the three-dimensional structure of DNA, and how it was being transcribed in general or at any given time.  This is changing, and RNA sequencing is part of an effort to understand what is happening in the transmission of genetic information in active cells.  Counting the amount of RNA material in a cell that relates to specific genes is an important goal of RNA sequencing.

## Assembled 'model' genomes

The full genetic sequence for an organism (or a model sequence, since all individual organisms have slightly different DNA) can be stored in an agreed library, available for researchers who want to work from this model (for genetic counting etc).  To carry out counting this is usually (though not always?) required.

A full genome can be a large computer file, since billions of genetic 'base pairs' are often found in the sequence.

Some scientists are working on even more basic science, like assembling genomes for plant animal organisms that have not been assembled before, to pave the way for further analysis like gene expression etc.  Announcements of new genomes for organisms are now much more frequent and common than they were (weekly), but a few decades ago, it took a significant amount of time to assemble even the first version of the human genome.

## Integrating this information to carry out gene-counting.

Provided we are only going to use the fragments that meet the quality thresholds, then the next step is to work out what these fragments refer to, in the context of the entire genome.  The large 'assembly' task that must occur before counting can occur is to assemble fragments of genes sufficiently and compare them against:
1. A pre-existing reference genome; and 
2. A reference file of genes (whether general or organism specific).

The counting process itself must consider the relationship between fragments and genes, and the conventional approach is to relate the genes to a genome, and the fragments to both of these.  The setup is:
1. We have a source genome.
2. A format exists in which genes of interest are 'annotated' along the whole source of the source genome. (the creation of an 'index').
3. Each fragment in the reads is located on the reference genome at a suitable place.
4. The number of fragments that are wholly (or in some cases, partly) overlapping these gene sections can be counted.

Of these, steps 2 and 3 may be time-consuming (3 in particular?). 

## How do we do the counts?

Programs like "STAR" have been written to carry out this complex task on a high-performance computer with both large memory, several processors, and high speed.   (The output of 1 and 2 could be saved as a composite for repeated 'counting' of fragments?). 

Whatever method is used, the end goal of these steps is to produce a list of genes (itself derived from the reference list of genes used with programs like STAR), and a list of cells (derived from the barcodes used in the library for the sequencing process), and then a count of every time a gene is matched to a cell.   

Even though there are thousands of genes and cells in some experiments, the number of combinations of these that actually carries any count value is quite low (...%?).  This fact is relevant to experimental design, because there has to be sufficient depth of reads to ensure that there are not only sufficient numbers of results, but that they are large enough to provide discrimination between low-levels of gene expression and high-levels of gene expression.

# What does a gene-vs-cell count matrix look like?

The conventional way to record how many times a gene sequence appears in a given molecule or cell is to use a large matrix, with gene names/identifiers as rownames, and cells/barcodes as column names.  Counts of the number of genes-detected-in-fragment are recorded for each (gene,cell) coordinate.  

There is more than one way to do carry out such a count, and more than one way of recording the resultant matrices in files on a computer.   

The output of gene counting processes stored in an explicit 2D matrix would, in theory, be a matrix with incredibly large dimensions, and many entries where there is no gene detected for a given cell.  One of the computational solutions to this is to work with sparse matrices, which are ways of describing matrices by reference to the data that is actually there.   

## pbmc10k data and Seurat

The pbmc10k data is explained in some 2019 Seurat source code [GitSource](https://github.com/satijalab/Integration2019/blob/master/preprocessing_scripts/pbmc_10k_v3.R) and uses this line to read in the data, in that case in H5 format:

```
counts <- Read10X_h5("raw_data/10x_scrna/pbmc10k_v3/pbmc_10k_v3_filtered_feature_bc_matrix.h5")
```

The actual code base there is linked to a paper bny Tim Stuart et al, 'Comprehensive integration of single-cell data', described here [Seurat2019](https://github.com/satijalab/Integration2019).  This information is very helpful in attempting to recreate the experimental analysis using the package, and gives some insights into how it might be combined with C3 type data (chromatin accessibility).

## Example 10X Genomics count data (sparse Matrix Market format)

A common format for a sparse matrix is the "Market Matrix" format, in which the genes for rownames are contained in one file, with names listed vertically, and another file in which the cells for colnames are contained in one file, with names listed vertically.   A third file contains only the coordinates of the output matrix (which correspond to the line numbers of the rowname and colname files) that have entries >0.  

Current practice is that 10X Genomics count data is provided in 3 files and uses the Market Matrix format - it essentially is a simple format to record sparse matrices (where there are lots of zero entries).   10X Genomics supplies data in the form of 3 files (.mtx and .tsv) that together make up the "Market Matrix" format.  {I have prepared a separate note on preparing count matrices and reading in Market Matrices}.

The .mtx format has a header line, with the matrix dimensions and the total number of entries in the .mtx file.  

The remainder of the entries are three columns, with:
```row col count```

# Bottlenecks

The contemporary problem, and bottlenecks were caused by the sudden availability of large amounts of sequencing 'read' data produced by 10X Genomics output using programs like CellRanger (and implicitly, STAR).  

When reading any paper on single cell analysis it helps to equate the number of reads to the number of cells in the experiment.  The number of reads will usually be mutliples of the number of cells.  This is based on the fact that each cell has several molecules, and reads are only fragments of molecules.

The scale of data is indicated by the fact there could be 1,000 reads per cell, and 1 thousand to a million cells in the analysis.  So keeping all of these initially unassembled read fragments in memory is onerous.  {Techniques for dealing with less of them are helpful, inspired by biological knowledge, but this also resembles a pure computer science problem}

The Kallisto article (2019) gives benchmark times for processing 785 million reads in 22 hours (and 1.5Tb of disk space) using CellRanger software (for 10X Genomics). The pbmc3k experiment often referred to for Seurat tutorials (discussed further below) has over 13,000 cells for example (which implies perhaps several hours of this pre-processing time, if done in that way). 

Part of the limitations in the processing time when doing full alignment before the counting occurs is that the memory usage is high (implying large amounts of the raw data have to be held within in-memory data structures to perform the task).   

## Kallisto and the pseudo-count approach : overcoming some bottlenecks

For those with access to (free/cheap) supercomputer time, and machines with lots of memory (e.g. > ) may not be immediately be averse to running full CellRanger/STAR alignment to obtain their read counts.   But what if you do not have time or resources, or simply want to do more with the resources you have under your control?

Kallisto's authors looked for way to reduce the instantaneous demands on memory (thereby helping to improve performance).  To do this, they chose to modify some of the assumptions about what needed to be done to achieve adequate gene 'counts', specifically full genome alignment.

In any case, kallisto is designed to apply the de Bruijn graph techniques to k-mers, instead of full reads, and thereby save on resources (it is called 'pseudo-alignment).  As a result, Kallisto and Salmon are capable of running quantification on a laptop computer, in reasonable time:

"kallisto, can be used to analyze 30 million unaligned paired-end RNA-Seq reads in less than 5 minutes on a standard laptop computer while providing results as accurate as those of the best existing tools."  (pre-print: https://arxiv.org/pdf/1505.02710.pdf) and published in [Nature2016](https://www.nature.com/articles/nbt.3519/)

Internally, Kallisto uses a new data structure for computation (involving cell barcodes, the molecular identifiers for fragments, and something called 'set': BUS=barcodes, umi, set).  The worktools were given the name "BUStools". [kallistobustools](https://www.kallistobus.tools)

Other programs like Kallisto/Salmon adopt a different approach to STAR, in that they try to eliminate the need to do steps 1 and 2, resulting in some time-saving.  The rationale is that the primary goal is 'counting', not specific alignment and indexing, so that steps 2 and 3 can be prioritised (or altered/substituted without significance effect on the outcome).

In the context of a workflow of single cell analysis and Seurat, it is worth noting that since Kallisto was developed, it has now applied the pseudo-counting idea specifically to single-cell analysis (2019).  See this: [2019bioXriv_paper](https://www.biorxiv.org/content/10.1101/673285v2.full.pdf).  In that paper the authors say:

"The quantification of transcript or gene abundances in individual cells from a single-cell RNA-seq(scRNA-seq) experiment is referred to as pre-processing"

'Pre-processing' is a term better understood  by an audience who already knows what they are doing, but the article is useful in explaining the motives for creating Kallisto, and why it works.  It helps to understand what the UMI markers mean, and how they might relate to 'transcripts' and original cell biology.  The article has some examples using the 'pbmc10k_v3' dataset (which differs slightly from pbmc3k used in pre 2019 Seurat tutorials, but is essentially same type of human data). 
Kallisto was created to assist by reducing the need for long time-delays and substantial computing power to achieve counts for analysis (ultimately, to do things like differential expression analysis).   

# Reading in Matrix Market count data to R

The R language ecosystem has different solutions for working with .mtx files, including the Matrix package.  Seurat objects can also work with sparse matrices created from 10X Genomics as an input source.

To begin your Seurat experiments with Market Matrix formatted count-data, download the pbmc data as recommended at the [SeuratTutePage](https://satijalab.org/seurat/archive/v3.0/pbmc3k_tutorial.html).  Seurat comes pre-installed with only a small version of this data (pbmc_small).  That tutorial illustrates the usefulness of Seurat to the specific goal of 'clustering', in order to find patterns in gene expression.

The Seurat package's main R fuction to create a Seurat object is 'CreateSeuratObject()'.  This uses matrix, or sparse matrix count data you already have available (in a data type recognisable to the R language environment), as an input parameter.  Before this occurs:

1. You can read in some count data into an intermediate matrix format.
2. Pre-processing of count data is still possible.

If you are using, for example, 10X Genomics *count data*, prepared by CellRanger or otherwise, then the data is not immediately available in a base R object, or in a format that can be used immediately to create a Seurat object. 

If you already have the required three Market Matrix files in a folder, you can first read them into an object recognised by R (a sparse matrix) using the Read10X function provided by Seurat.  Once you have this data object, you can then use it with the 'CreateSeuratObject' function to create the Seurat object.  

```{R}
# Load the PBMC dataset [note Seurat comes with a pbmc_small example but since it has already had some preprocessing steps applied to it, this file provides an illustration with less in-built assumptions]
# download the pbmc data as recommended at the [SeuratTutePage](https://satijalab.org/seurat/archive/v3.0/pbmc3k_tutorial.html).  Seurat comes pre-installed with only a small version of this data (pbmc_small). 
# When you have downloaded the data and put it into the folders as described below, run this script:
pbmc.data <- Read10X(data.dir = "../data/pbmc3k/filtered_gene_bc_matrices/hg19/")
```


## Further processing of matrix output of Read10X and creation of Seurat object

By the time that some gene-vs-cell count data has been prepared, quality control of the sequencing data will already have been done, based on the 'Q' (quality) scores in FASTQ format files.  This does not mean that further quality-control is not necessary or possible once the gene-vs-cell count data is obtained.  It may be difficult to do this on raw format like .mtx, so it seems best to do it once you have been able to read the data into R in some way.

Some minor pre-processing of *count data* before creation of a Seurat object can be done by the R programming language; it can even be done as part of using functions like 'Read10X', which is provided by the 'Seurat' package, but is not dependent upon the prior creation of a Seurat object.

If there are basic concerns with the quality of the *count data* (e.g. very low counts, or genes), then these can be filtered out of the data that is used to create the initial Seurat object.  

The Seurat package provides for this by allowing some parameters in its CreateSeuratObject to be used to filter some cells. (e.g. low cell numbers or features)

```{R}
# Create Seurat object
pbmc <- CreateSeuratObject(counts = pbmc.data, project = "pbmc3k", min.cells = 3, min.features = 200)
```


## The count data once it is inside the Seurat object

Rather than rely on R's matrices alone, the Seurat object manages the gene-vs-cell count information within smaller objects called Assays.   Assays also contain one or more versions of cell count information, each being R's "Matrix" data type or similar.  All of these Matrices will have the genes as rownames, and then the cell names as columns with the count data (number of times a gene was counted in a given cell).  The columns represent numeric vectors in R.  

Whilst Seurat can filter cell rows based on conditions, the intention seems to be not to vary the dimensions of the matrices presents in the Assay objects (throughout the further filtering work (otherwise Seurat package complains). 

The use of the CreateSeuratObject() function actually does two things: 1. It creates an Assay object to hold the data 2. It creates a Seurat object and includes this new Assay as the DefaultAssay() in the Seurat object.

Once a Seurat object has been created, and an Assay object has also been created to hold the gene-v-cell count data, that data is available to both the Assay object functions and the Seurat object functions.  It is also a data type that can be accessed using R's ordinary matrix functions.

```{R}
# How to get your default 'counts' matrix data
myassay<-GetAssayData(pbmc,slot="counts")
# Or the fuller form is:
myassay<-GetAssayData(pbmc,assay="RNA",slot="counts")
```

## Modification and updating of count data inside the Seurat object

The Seurat object has been designed to wrap these matrix-like data arrays inside an object called an "Assay", and then to store Assays inside the Seurat object.   For small projects, the Assay object might hold 3 similar data matrices, each one differing by some transformation such as scaling or normalistion (thereby preserving the experimenter's work methods).   In larger projects, there may be more than one Assay object.

# Managing user-defined categories and cell-specific information.

The Seurat object has two main different forms of data structures, distinguished by:
1. The matrices containing gene-vs-cell counts (contained in the Assay objects).  These have genes as rownames; and 
2. The data.frame with cells as rownames (contained in the meta.data slot of the main Seurat object).

A data.frame is the main 2D data structure in base R.  

# Comparison of Seurat obejct to another popular Object for single cell analysis

Seurat is not the only package-based set of tools for holding single cell analysis data.  What is common, by necessity, is that the object hold raw counts in 'assays', and has some capacity to hold metadata (and category information) for individual cells and/or genes.

For comparison, see [SCE_Bioconductor](http://bioconductor.org/books/release/OSCA/data-infrastructure.html#background).  You can compare the Seurat object to the R Object called a 'singleCellExperiment' (SCE), created by David Risso and Aaron Lun, used in the Bioconductor projects.   There is a similarity in that the SCE object an 'assay' matrix(?) for raw data that has genes as rows, and cells as collumns, but there are also independent meta-data objects for both cells and features.   Recognising the need for converting these objects, Satija lab has a [ConversionGuide](https://satijalab.org/seurat/articles/conversion_vignette.html) on how to convert from Seurat over to singleCellExperiment (and vice versa).

# The main data.frame in the Seurat object

There is one central data.frame in the main Seurat object which is intended to help manage information specific to each cell.  This is the data.frame contained in the objectname@meta.data slot.  

```
NB: There was a deliberate change in Seurat v3 compared to Seurat v2, which modifies the normal operation of accessing the data.frame object inside the @meta.data slot (something that might confuse regular R users).  See https://satijalab.org/seurat/articles/essential_commands.html  The 'pbmc@meta.data' data frame can be referenced just by 'pbmc' and a column in that data.frame can, for example, be referenced by pbmc$nCount_RNA instead of pbmc@meta.data@nCount_RNA.  This shorthand is possible because the data.frame in the @meta.data slot is the only data.frame in the Seurat object that is used for management of cellular information, outside of Assays.  Users do not even need to name this data-frame in R: they simply refer to the slot it is held in.  
```

As soon as a Seurat object has a valid Assay object, with count data, added to it, the main data.frame will be populated with at least 3 columns, which if our Assay was called 'RNA', would be named:

```orig.ident nCount_RNA nFeatures_RNA ```

In the simplest case, there will be one raw count Matrix inside an Assay (e.g. an Assay called 'RNA'), which will not yet have been scaled or altered.  This one Assay will initially be the only Assay inside the Seurat Project object. 

The Seurat object as a whole is more complicated, with several slots (properties), including "assay", which is merely a list of the enclosed Assay object.  The reason it is more complicated is that the Seurat object has been designed to record changes in the state of the cell filtering (identity) information, as well as the transformations of the raw count data.  It has also been designed to provide functions to make these changes easier.

## Management of identities for clustering 

The Seurat object has been designed on the basis that (at least) one of its main data.frame's columns will contain classification or identity information about each cell, for subsetting, filtering, clustering or other analysis goals.  

The Seurat object,by its main data.frame, allows users to keep entire vectors or factors corresponding to all cells, which have individual classification schemes held within them.  Users may wish to switch between these, or copy from them, for different purposes. 

The Seurat object leverages the base R 'factor' type for this classification and clustering: it expects that each one of the thousands of cells will be coded with a 'level', drawn from the master set of 'levels'.  This mapping of cells to 'levels' is captured in a single 'factor', similar to a numerical vector, which can be stored in a column of the main data.frame (the one held in the Seurat object's meta.data slot).  The main data.frame has all the cellnames as rownames.  

The Seurat object function 'Idents()' facilitates consistency and re-use by forcing any data.frame column that is used to specify an identity data column to take on R's 'factor' type, even if the column is not a factor type.  The default factor ('orig.ident') is, however, already a factor type.

```{R}

head(pbmc@meta.data,20) # check first 20 entries of 2700
```

## Internal structure of Seurat object

```{R}
# General exploration of the features of the Seurat object
nrow(pbmc) #13714  - this is the Assay dimension, since rows = number of genes/features here
ncol(pbmc) #2700
slotNames(pbmc) # helpful command for understanding Seurat object's general properties
```

The 'assays' slot comprises a list of one or more Assay objects
```{R}
pbmc@project.name # same name as project name given at time of creation of Seurat object
pbmc@assays
class(pbmc@assays) # this is a list
pbmc@active.assay  # 'RNA' ; just a name that describes the current Assay object
class(pbmc@active.assay)  #  (character) 
 # this is summary description of the first Assay
class(pbmc@assays[1]) # first line is 'list' because that's what's being expanded
pbmc@assays['RNA']  # This is one way of accessing an Assay, but we can also use pbmc@assays[1]
```

The internal structure of a Seurat object (version 4) will look something like this:

-->meta.data (holding a dataframe)
	-->rows include: cell names (barcodes)
	-->1 column is : orig.ident (a factor, which may initially only have 1 level: projectname)
	-->2 columns include : $nCount_RNA, $nFeatures_RNA (for the Assay 'RNA')
	(each having statistics about the counts in the current Assay)
	
--->assay (list of Assay objects)
		--->Assay[1]
			--->counts(default Matrix), scale.data, data
			(rownames are gene/feature names)
			(colnames are cell barcodes)
			
--->active.ident  (pointer to the active 'identity' data for clustering)
                 (may be created from column in main data.frame, e.g. orig.ident)
                 (may also be changed to point to another column of data.frame, later in project)


If we refer specifically to the active.ident (extract it from the data.frame, as a factor), it is single dimension, with cells as rownames:

```{R}
head(pbmc@active.ident,20)  #  list all Cells and their identity (i.e. here, a subset, and only 1 level)
```

## Using filtering by inspection of cell-names and counts (e.g. counts for MT cells)

Further recommended pre-processing for quality control [see Ref in Dave Tang's blog] is to inspect for consequences of cells leaking mitochondrial material i.e. *relatively* high MT gene percentages per cell.

The suggestion is to use the count matrix that is already read in to an Assay (i.e. already R object created by Read10X).    By preparing a quantiative measure of MT-gene concentration in gene counts, and putting this into the main data.frame, there is a convenient property to filter cells by (ie thresholds, or percentages).  This makes use of Seurat's data.frame that already has all the cells listed as rownames.

Note that this is a fairly simple approach.  Genes that might have originated in mitichondria but associated with nucleus might not have been named in this way.  See [SeuratMT](https://github.com/satijalab/seurat/issues/3508)

```{R}
# mitochondria genes conveniently start with MT
myassay<-GetAssayData(pbmc,slot="counts") # already done at line 186 above
mito.genes <- grep(pattern = "^MT-", x = rownames(x = myassay), value = TRUE)
length(mito.genes) # 13 genes with MT (mitochondrial name)

# now to perform vector division on colnames (i.e. colSums = horizontal vector calculations).
# in effect, this is the gene count subtotal - only MT-filtered rownames for each barcode
mygenecount<-Matrix::colSums(myassay[mito.genes, ]) 
mycellcount<-Matrix::colSums(myassay)  # this is the total gene count (all rows, by cell)
mt.perc<-mygenecount/mycellcount # vector division, element by element

# end result is a single vector having as many entries as there are columns (i.e. cell barcodes)
head(mt.perc,20) # just first 20 of 2700 entries
```


How is this filter captured for persistence?  Is there an identity created?  See below.

```{R}
# We conveniently have a vector with a score for each cell. Orientation irrelevant in 1D.
# We can store the mt.perc (but now vertically) in the main data.frame, using new colName 'mt.pc'
pbmc@meta.data$mt.pc<-mt.perc

```

The Seurat object's main data.frame will now contain an extra column, with these entries:

```{R}
head(pbmc@meta.data,20) # check first 20 entries of 2700
```

Now we may want to interpret this information for quality purposes.  When using Seurat, be aware that its custom functions (like Violin Plot) will often attempt to help users by making use of the main data.frame (since it uses cells as rownames).  Also, the ability to put Violin Plots side by side is that each one is essentially a distribution plot, so relative shapes, skewness can be compared, even if absolute values of the data are different.

```{R}
# We can do a Violin plot, using the data.frame vectors as the input vector
# This will show the distribution of each type of numeric vector, as well as median, mean
# Skewness is apparent, as well as outliers (that lie outside the boundary of the plot)
# See: https://towardsdatascience.com/violin-plots-explained-fb1d115e023d
# This is Seurat 4.0's implementation of the function, and it uses the meta.data data.frame
VlnPlot(pbmc,features=c("nCount_RNA","nFeature_RNA","mt.pc"),assay="RNA",ncol=3)
```


```{R}
# Now that we have this quantitative metric, we can do further filtering on cellnames if we want topo.colors()
# Seurat makes this easier by including a function 'FilterCells()' that accepts the data.frame columns, and the thresholds (high,low) for each
```

# Graphical inspection of the genes (features) data in the Seurat object

The Seurat object has a few functions allowing us to examine specific genes, or gene groups.  In each of these, the cells will be coloured as per the legend, with whatever the current 'identity' levels are.  Also, the underlying gnee-v-cells count matrix used for the specified Seurat object will be extracted via the 2 levels of Seurat objects in this way:
(a) the Default Assay is used;
(b) the 'counts' matrix inside that Assay is used by default.   

Both these settings can be changed by modifying the parameters in the functions, and is likely to be necessary as the work progresses.

Some of the functions in Seurat have been derived from particular examples or calculation needs at a particular point in the assumed process, like being able to calculate the percentage of genes with a certain name pattern (e.g. MT something, for mitochondrial genes), or a particular feature (gene).   The authors have generalised about this use case, but they have retained the original context, by assuming that the assay chosen will be using its 'counts' slot (and not scaled.data etc).   As explained in the Seurat Help, a function like 'PercentageFeatureSet' has these features and context:
```
This function enables you to easily calculate the percentage of all the counts belonging to a subset of the possible features for each cell. This is useful when trying to compute the percentage of transcripts that map to mitochondrial genes for example. The calculation here is simply the column sum of the matrix present in the counts slot for features belonging to the set divided by the column sum for all features times 100.
```

The Help manual also goes on to explain that you can set another column in the meta.data data.frame, but in that case it will return a completely new 'Seurat object'  with the proportion of the feature set now in the meta.data??

To check this function we can carry out these vector calcs in base R:
Remember: "The calculation here is simply the column sum of the matrix present in the counts slot for features belonging to the set divided by the column sum for all features times 100."  This means 'the counts slot' of the currently selected Assay.


```{R}
myassay<-GetAssayData(pbmc) # default Assay, default sparse counts matrix
```

When we test the output of the PercentageFeatureSet function, notice that the output is not completely precise.   For a start, we obtain a 'data.frame', with 'nCount_RNA' as the colname.  The output actually contains percentages, not the nCount of genes.  Also, it provides you with a data.frame format, because it is useful for inserting into the Seurat object's data.frame.  But the 'counts' in the Assay object is not a data.frame, so the program has to do more work.

If we didn't have this function how we would work on the Seurat data matrices in the Assay object, using base R, to return the feature count percentage for a single gene (single row in the Assay matrices)?  In base R, if we wanted to work on the Assay's count object, and return the same information, we would specify:
(1) drop=FALSE when subsetting the Assay's matrix, which preserves its original dimensions, otherwise it just returns a numeric vector for single row
(2) force the 'matrix' to be a data.frame (i.e. unlike vector, has 'column names' for indexing)
(3) Fix the orientation/shape of the output data.frame

Here the data.frame we produce is a wide one (lots of columns), which means that the data.frames 'list' of column vectors is 1 row and 2700 columns, as per the matrix, but the desired orientation for the Seurat data.frame is 2700 (cellname) rows and 1 column).  

Since we are just doing rotation (and not collecting repeated entries as per reshape() or melt() we can use the base R transpose function: t())

(4) Fix the column heading.  

```{R}
# single row of counts for for this gene across 2700 cells, as a dataframe
# c<-b['SCAMP3']  # This [ ] method retains the single column data.frame.  c<-b$SCAMP3 would not
#genecounts1<-as.data.frame(myassay['RPL13A',,drop=FALSE])
# myassay<-as.data.frame(GetAssayData(pbmc,slot='counts')) #obtain specific matrix (huge)
# pull just the column at the outset 
myassay<-GetAssayData(pbmc,slot = 'counts')
genecounts1<-as.data.frame(myassay['RPL13A',,drop=FALSE])
class(genecounts1) # dataframe
#denom<-sum(genecounts)    # Matrix::colSums(myassay) # sums of counts for all genes, all columns
countstotal<-Matrix::colSums(myassay) # summing a vector by cells (total of counts for all genes)
percFeature<-(genecounts1/countstotal)*100 # the calculation
newdf<-t(percFeature) # transpose to make a long, not a wide data.frame and store it in newdf
colnames(newdf)<-'nCount_RNA' # optional, for Seurat object comparison
head(newdf,10) # show first few entries of result, to compare to Seurat function
```

Seurat makes all of this easier by having a 'PercentageFeatureSet()' function to return the same data, but this time as a data frame.  You can do this for genes matching a pattern but also for single gene (feature):

```{R}
output<-PercentageFeatureSet(object=pbmc,features='RPL13A')
class(output) # dataframe
head(output,10)
```

To see how it was actually implemented in Seurat, you can visit [SeuratGithub](https://github.com/satijalab/seurat/tree/master/R)

If we plot two different genes (features) against one another we can see if they have a linear relationship, or independence. The pearson correlation for these is displayed automatically.
```{R}
# visualisation of selected genes (features)
# Pearson correlation between the two features is displayed above the plot.
FeatureScatter(object=pbmc,feature1="RPL13A", feature2="MRPL9")  # feature 1 on x axis
FeatureScatter(object=pbmc,feature1="RPL13A", feature2="SCAMP3") # gap at scamp 0.5?
```

Does this data make sense?  There appears to be plot 'dithering', in that all the SCAMP3 values are either 0,1 or 2 exactly, but they are spread out here. (can this setting be changed?).  Under the bonnet, it appears to use geom_jitter from ggplot [labinfo](https://github.com/satijalab/seurat/issues/86).

The RPL13A cells vary between 0 and 150 (most are less than 100). The majority of these RPL13A are not really overlapping genes: most coincide with SCAMP3=0.  A small number are split between SCAMP3=1 and SCAMP3=2. 

SCAMP3 is a human gene, one of the producers of "secretory carrier membrane proteins" (see [wiki](https://en.wikipedia.org/wiki/SCAMP3)

Let's just look at results for SCAMP3, with a total of 255 counts :
```{R}
scampgen<-as.data.frame(myassay['SCAMP3',,drop=FALSE])
scampgen
sum(scampgen) #
```


There is a Seurat function that can calculate the row sums inside an Assay object (i,.e. number of counts of genes, which results in a vector, or you can specify the rowname):
```{R}
y<-rowSums(pbmc,na.rm=FALSE,dims=1,slot='counts')
y['SCAMP3']  # 251 counts
```

It turns out that only 10% of cells show a count for this gene, and even then, any given cell's total gene counts linked to these genes is often <0.1%
```{R}
output<-PercentageFeatureSet(object=pbmc,features='SCAMP3')
output
y<-output[output$nCount_RNA>0,,drop=FALSE] # in subsetting, use drop to preserve data.frame
y
```

So try again, plotting only those cells that have actual values for SCAMP3.  Fortunately, the FeatureScatter() function provided by Seurat allows the cells we want to be specified, so if we obtain some new cell groups (or split in some way), we might be able to group cells according to how many SCAMP3 cells they have?

Before doing base R or any individual filtering by SCAMP3 genes, note that there is a way to filter by nFeatures (total gene counts per cell, rather than counts per gene), that will help by analogy:

```{R}
# This produces a new Seurat object that is a subset (replaces our original set)
# Compare to example in https://satijalab.org/seurat/articles/pbmc3k_tutorial.html
# old: (2019) https://satijalab.org/seurat/archive/v3.0/pbmc3k_tutorial.html
pbmc <- subset(pbmc, subset = nFeature_RNA > 200 & nFeature_RNA < 2500)
```

What's the count of SCAMP3 across all cells?  Need to refer to the Assay data
```{R}
a<-GetAssayData(pbmc,slot='counts')
sum(a['SCAMP3',]>0,drop=FALSE) # 238

```

Can we create a list of cells, from the Assay data, where those cells have >1 SCAMP3 gene counts?

Let's say we are using a data.frame.  A data.frame acts as a set of lists, so when a data.frame is reduced to one column (one list), R by default reduces the dimensions back to a list-like object (not a data.frame).  When using the x$name syntax you are pulling out the column as if it were a list.

```{R}
a<-GetAssayData(pbmc,slot='counts')
#rownames(a) # list of genes
# what if we tranpose the matrix (resource heavy), then filter ?
b<-as.data.frame(t(a)) # making it a dataframe helps process by column, instead of list-like matrix?
# b is a 2679 x 13714 dataframe (cells x genes)
#keep only one column
# [ ] method retains the single column data.frame.  c<-b$SCAMP3 would not
# so [] with dataframe can take as argument a list of df values, using $, for expressions:
ss<-b[b$SCAMP3>0,,]  #238 out of 2679 rows with all columns. So rownames ok.
ss['SCAMP3']
# one step: LHS subsets to create a new df, then the RHS select column
ss<-b[b$SCAMP3>0,,]['SCAMP3']  # TO DO: see if subset() in base R better
cellset<-rownames(ss)  # list of row names to use
```

The cellset defined above can be used in the WhichCells function (see below).  This is a subset of rownames from our meta.data cells.

Can we obtain some stats on the SCAMP scores?
```{R}
summary(ss) # min, max, mean, quartile so no need for min(ss) and max(ss)
summary(b['SCAMP3']) # This is the original column, not filtered for positives
```

The subset of SCAMP3 and RPL13A) (with only those cells with SCAMP3>0 plotted against RPL13A).  There is still an artifical scatter going on here - all the SCAMP3 counts are exactly 1 or 2.

```{R}
FeatureScatter(object=pbmc,feature1="RPL13A", feature2="SCAMP3",cells = cellset) 
```


Another helper function which allows you to work with a subset of cells (and then check other criteria using idents etc).  If you only specify a list of cells as the 'cells' parameter you effectively get back what you give the function:

The following code needs debugging FROM HERE:--->

{R}
outcome<-WhichCells(object=pbmc,cells = cellset)
outcome

We have now succeeded in being able to work with a subset of cells, which we have not yet given an 'identity' (but could do so).   Let's modify the original identity set:
{R}
SetIdent(pbmc,cells=cellset,value=c("SCAMPY"))
Check:

{R}
outcome<-WhichCells(object=pbmc,idents = "SCAMPY")
outcome

<-----TO HERE




```{R}
pbmc@meta.data['orig.ident'][pbmc$orig.ident!="pbmc3k",,drop=FALSE]
```


```{R}
# This produces a new Seurat object that is a subset (replaces our original set)
# Compare to example in https://satijalab.org/seurat/articles/pbmc3k_tutorial.html
# How many total genes?
pbmc <- subset(pbmc, subset = nFeature_RNA > 300 & nFeature_RNA < 2500)
output<-PercentageFeatureSet(object=pbmc,features='SCAMP3')
output
y<-output[output$nCount_RNA>0,,drop=FALSE] # in subsetting, use drop to preserve data.frame
y
```